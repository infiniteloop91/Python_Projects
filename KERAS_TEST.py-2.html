
# coding: utf-8

# In[12]:

import numpy as np
from random import randint
from sklearn.preprocessing import MinMaxScaler


# In[13]:

train_labels = []
train_samples = []


# In[14]:

for i in range(50):
    random_younger = randint(13,64)
    train_samples.append(random_younger)
    train_labels.append(1)
    
    random_older = randint(66,100)
    train_samples.append(random_older)
    train_labels.append(0)
    
for i in range(1000):
    random_younger = randint(13,64)
    train_samples.append(random_younger)
    train_labels.append(0)
    
    random_older = randint(66,100)
    train_samples.append(random_older)
    train_labels.append(1)


# In[15]:

for i in train_samples:
    print(i)


# In[16]:

for i in train_labels:
    print(i)


# In[17]:

train_labels = np.array(train_labels)
train_samples = np.array(train_samples)


# In[18]:

scaler = MinMaxScaler(feature_range=(0,1))
scaled_train_samples = scaler.fit_transform((train_samples).reshape(-1,1))


# In[19]:

for sample in scaled_train_samples:
    print(sample)


# In[20]:

import keras 
from keras import backend as k
from keras.models import Sequential
from keras.layers import Activation 
from keras.layers.core import Dense
from keras.layers import Activation, Dense
from keras.optimizers import Adam
from keras.metrics import categorical_crossentropy 


# In[21]:

model = Sequential([Dense(16, input_shape=(1,), activation='relu'),
                   Dense(32, activation='relu'),
                   Dense(2, activation='softmax')
                   ])


# In[22]:

model.summary()


# In[23]:

model.compile(Adam(lr=.001),loss='sparse_categorical_crossentropy',metrics=['accuracy'])


# In[27]:

model.fit(scaled_train_samples, train_labels, validation_split=0.1, batch_size=10,epochs=20,shuffle=True, verbose=2)


# In[29]:

test_labels = []
test_samples = []


# In[30]:

for i in range(10):
    random_younger = randint(13,64)
    test_samples.append(random_younger)
    test_labels.append(1)
    
    random_older = randint(66,100)
    test_samples.append(random_older)
    test_labels.append(0)
    
for i in range(200):
    random_younger = randint(13,64)
    test_samples.append(random_younger)
    test_labels.append(0)
    
    random_older = randint(66,100)
    test_samples.append(random_older)
    test_labels.append(1)


# In[31]:

test_labels = np.array(test_labels)
test_samples = np.array(test_samples)


# In[32]:

scaler = MinMaxScaler(feature_range=(0,1))
scaled_test_samples = scaler.fit_transform((test_samples).reshape(-1,1))


# In[34]:

predictions = model.predict(scaled_test_samples, batch_size=10, verbose=0)


# In[36]:

for predictions in predictions:
    print(predictions)


# In[38]:

round_predictions = model.predict_classes(scaled_test_samples, batch_size=10, verbose=0)


# In[39]:

for predictions in round_predictions:
    print(predictions)


# In[41]:

get_ipython().run_line_magic('matplotlib', 'inline')
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix
import itertools


# In[42]:

cm = confusion_matrix(test_labels, round_predictions)


# In[43]:

def plot_confusion_matrix(cm, classes,
                          normalize=False,
                          title='Confusion matrix',
                          cmap=plt.cm.Blues):
    """
    This function prints and plots the confusion matrix.
    Normalization can be applied by setting `normalize=True`.
    """
    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print("Normalized confusion matrix")
    else:
        print('Confusion matrix, without normalization')

    print(cm)

    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    fmt = '.2f' if normalize else 'd'
    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, format(cm[i, j], fmt),
                 horizontalalignment="center",
                 color="white" if cm[i, j] > thresh else "black")

    plt.ylabel('True label')
    plt.xlabel('Predicted label')
    plt.tight_layout()


# In[44]:

cm_plot_labels = ["no side effects", "side effects"]
plot_confusion_matrix(cm, cm_plot_labels, title="The Matrix")


# In[ ]:



